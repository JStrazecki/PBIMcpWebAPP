"""
MCP tools for automatic dataset discovery - exact replicas of working custom DAX queries
"""

import json
from datetime import datetime
from fastmcp import FastMCP

from ...powerbi.client import get_powerbi_client  
from ...utils.logging import mcp_logger


def register_discovery_tools(mcp: FastMCP):
    """Register discovery tools that work exactly like successful custom DAX queries"""
    
    @mcp.tool()
    def auto_discover_workspace_info(
        workspace_name: str,
        dataset_name: str,
        force_refresh: bool = False
    ) -> str:
        """
        AUTO-DISCOVERY: Get workspace and dataset information.
        """
        try:
            mcp_logger.info(f"Auto-discovering workspace info: {workspace_name}/{dataset_name}")
            
            client = get_powerbi_client()
            workspace = client.get_workspace_by_name(workspace_name)
            dataset = client.get_dataset_by_name(workspace['id'], dataset_name)
            
            output = f"üè¢ AUTO-DISCOVERY: Workspace Information\n"
            output += f"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
            output += "=" * 60 + "\n\n"
            
            output += f"üìä WORKSPACE DETAILS:\n"
            output += f"‚Ä¢ Name: {workspace['name']}\n"  
            output += f"‚Ä¢ ID: {workspace['id']}\n"
            output += f"‚Ä¢ Type: {workspace.get('type', 'Workspace')}\n\n"
            
            output += f"üìã DATASET DETAILS:\n"
            output += f"‚Ä¢ Name: {dataset['name']}\n"
            output += f"‚Ä¢ ID: {dataset['id']}\n"  
            output += f"‚Ä¢ Configured Target: Server mode (Direct Lake/Import)\n\n"
            
            # Test basic connectivity
            try:
                test_dax = "EVALUATE { 1 }"
                result = client.execute_dax_query(workspace['id'], dataset['id'], test_dax)
                output += f"‚úÖ CONNECTION STATUS: Active and ready\n"
                output += f"‚úÖ DAX QUERIES: Supported\n"
            except Exception as test_error:
                output += f"‚ùå CONNECTION STATUS: Issues detected\n"
                output += f"‚ùì Error: {str(test_error)[:100]}...\n"
            
            return output
            
        except Exception as e:
            error_msg = f"‚ùå Auto-discovery failed for workspace info: {str(e)}"
            mcp_logger.error(error_msg)
            return error_msg
    
    @mcp.tool()
    def auto_discover_measures(
        workspace_name: str,
        dataset_name: str,
        force_refresh: bool = False
    ) -> str:
        """
        AUTO-DISCOVERY: Discover measures using EXACT working DAX query from logs.
        """
        try:
            mcp_logger.info(f"Auto-discovering measures: {workspace_name}/{dataset_name}")
            
            client = get_powerbi_client()
            workspace = client.get_workspace_by_name(workspace_name)
            dataset = client.get_dataset_by_name(workspace['id'], dataset_name)
            
            # Use EXACT query from successful logs (line 247)
            measures_query = "EVALUATE CALCULATETABLE( SELECTCOLUMNS(__def_Measures, [Name], [Description], [DisplayFolder]), NOT(ISBLANK(__def_Measures[Description])) )"
            
            result = client.execute_dax_query(workspace['id'], dataset['id'], measures_query)
            
            output = f"üìä AUTO-DISCOVERY: Dataset Measures\n"
            output += f"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
            output += "=" * 60 + "\n\n"
            
            # Parse result exactly like execute_custom_dax does in query_tools.py
            results = result.get("results", [])
            if results and "tables" in results[0]:
                tables_data = results[0]["tables"]
                if tables_data and len(tables_data) > 0 and "rows" in tables_data[0]:
                    rows = tables_data[0]["rows"]
                    output += f"üéØ DISCOVERED {len(rows)} MEASURES:\n\n"
                    
                    # Group by display folder - exactly like successful logs show
                    folders = {}
                    for row in rows:
                        measure_name = row.get('__def_Measures[Name]', '')
                        description = row.get('__def_Measures[Description]', '')
                        display_folder = row.get('__def_Measures[DisplayFolder]', 'Other')
                        
                        if display_folder not in folders:
                            folders[display_folder] = []
                        folders[display_folder].append((measure_name, description))
                    
                    # Show by folder - matches successful response format
                    for folder_name, measures in folders.items():
                        emoji = "üí∞" if "Income" in folder_name else "üìä"
                        output += f"{emoji} {folder_name}:\n"
                        for measure_name, description in measures:
                            output += f"  ‚Ä¢ {measure_name}\n"
                            if description:
                                output += f"    üìù {description}\n"
                        output += "\n"
                    
                    output += "‚ö†Ô∏è CRITICAL: ALWAYS use these existing measures for calculations!\n"
                    output += "‚ö†Ô∏è NEVER recreate measures that already exist!\n"
                else:
                    output += "‚ùå No measures found in response structure\n"
            else:
                output += "‚ùå No measures discovered\n"
                output += "Possible issues:\n"
                output += "‚Ä¢ Model permissions restricted\n"
                output += "‚Ä¢ Dataset refresh needed\n"
                output += "‚Ä¢ Network connectivity problems\n"
            
            return output
            
        except Exception as e:
            error_msg = f"‚ùå Auto-discovery failed for measures: {str(e)}"
            mcp_logger.error(error_msg)
            return error_msg
    
    @mcp.tool()
    def auto_discover_schema(
        workspace_name: str,
        dataset_name: str,
        force_refresh: bool = False
    ) -> str:
        """
        AUTO-DISCOVERY: Discover schema using EXACT working DAX queries from logs.
        """
        try:
            mcp_logger.info(f"Auto-discovering schema: {workspace_name}/{dataset_name}")
            
            client = get_powerbi_client()
            workspace = client.get_workspace_by_name(workspace_name)
            dataset = client.get_dataset_by_name(workspace['id'], dataset_name)
            
            output = f"üèóÔ∏è AUTO-DISCOVERY: Model Schema\n"
            output += f"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
            output += "=" * 60 + "\n\n"
            
            # Use EXACT query from successful logs (line 171)
            tables_query = "EVALUATE CALCULATETABLE( SELECTCOLUMNS(__def_Tables, [Name], [Description]), NOT(ISBLANK(__def_Tables[Description])) )"
            
            tables_result = client.execute_dax_query(workspace['id'], dataset['id'], tables_query)
            
            # Parse result exactly like execute_custom_dax does
            results = tables_result.get("results", [])
            if results and "tables" in results[0]:
                tables_data = results[0]["tables"]
                if tables_data and len(tables_data) > 0 and "rows" in tables_data[0]:
                    table_rows = tables_data[0]["rows"]
                    output += f"üìä DISCOVERED {len(table_rows)} TABLES:\n\n"
                    
                    # Format exactly like successful response
                    for row in table_rows:
                        table_name = row.get('__def_Tables[Name]', '')
                        description = row.get('__def_Tables[Description]', '')
                        
                        # Classify table type based on description
                        if 'fact' in description.lower() or 'transaction' in description.lower():
                            emoji = "üéØ"
                            table_type = "(Fact Table)"
                        elif 'dimension' in description.lower() or any(dim in table_name.lower() for dim in ['_date', 'accounts', 'contacts', 'mapping']):
                            emoji = "üìã"
                            table_type = "(Dimension)"
                        else:
                            emoji = "üìä"
                            table_type = ""
                        
                        output += f"  {emoji} {table_name} {table_type}\n"
                        if description:
                            output += f"    üìù {description}\n"
                        output += "\n"
                    
                    # Get columns using EXACT query from successful logs (line 208)
                    columns_query = "EVALUATE CALCULATETABLE( SELECTCOLUMNS(__def_Columns, [Table], [Name], [Description]), NOT(ISBLANK(__def_Columns[Description])) )"
                    
                    columns_result = client.execute_dax_query(workspace['id'], dataset['id'], columns_query)
                    
                    # Parse columns result exactly like successful response
                    col_results = columns_result.get("results", [])
                    if col_results and "tables" in col_results[0]:
                        col_data = col_results[0]["tables"]
                        if col_data and len(col_data) > 0 and "rows" in col_data[0]:
                            column_rows = col_data[0]["rows"]
                            output += f"üîç KEY COLUMNS BY TABLE:\n\n"
                            
                            # Group columns by table - matches successful format
                            tables_columns = {}
                            for row in column_rows:
                                table_name = row.get('__def_Columns[Table]', '')
                                column_name = row.get('__def_Columns[Name]', '')
                                description = row.get('__def_Columns[Description]', '')
                                
                                if table_name not in tables_columns:
                                    tables_columns[table_name] = []
                                tables_columns[table_name].append((column_name, description))
                            
                            # Show columns exactly like successful response
                            for table_name, columns in tables_columns.items():
                                output += f"üìã {table_name}:\n"
                                for column_name, description in columns:
                                    output += f"  ‚Ä¢ {column_name}\n"
                                    if description:
                                        output += f"    üìù {description}\n"
                                output += "\n"
                    
                    # Get relationships using EXACT query from successful logs (line 271)
                    relationships_query = "EVALUATE CALCULATETABLE( SELECTCOLUMNS(__def_Relationships, [Relationship]), __def_Relationships[IsActive] = TRUE() )"
                    
                    rel_result = client.execute_dax_query(workspace['id'], dataset['id'], relationships_query)
                    
                    # Parse relationships result exactly like successful response
                    rel_results = rel_result.get("results", [])
                    if rel_results and "tables" in rel_results[0]:
                        rel_data = rel_results[0]["tables"]
                        if rel_data and len(rel_data) > 0 and "rows" in rel_data[0]:
                            rel_rows = rel_data[0]["rows"]
                            output += f"üîó RELATIONSHIPS ({len(rel_rows)}):\n\n"
                            
                            # Format exactly like successful response
                            for row in rel_rows:
                                relationship = row.get('__def_Relationships[Relationship]', '')
                                output += f"  ‚Ä¢ {relationship}\n"
                            output += "\n"
                        
                else:
                    output += "‚ùå No tables found in response structure\n"
            else:
                output += "‚ùå No tables discovered\n"
                output += "Schema access may be restricted or model unavailable\n"
            
            return output
            
        except Exception as e:
            error_msg = f"‚ùå Auto-discovery failed for schema: {str(e)}"
            mcp_logger.error(error_msg)
            return error_msg
    
    @mcp.tool()
    def auto_discover_relationships(
        workspace_name: str,
        dataset_name: str,
        force_refresh: bool = False
    ) -> str:
        """
        AUTO-DISCOVERY: Discover relationships using EXACT working DAX query from logs.
        """
        try:
            mcp_logger.info(f"Auto-discovering relationships: {workspace_name}/{dataset_name}")
            
            client = get_powerbi_client()
            workspace = client.get_workspace_by_name(workspace_name)
            dataset = client.get_dataset_by_name(workspace['id'], dataset_name)
            
            output = f"üîó AUTO-DISCOVERY: Model Relationships\n"
            output += f"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
            output += "=" * 60 + "\n\n"
            
            # Use EXACT query from successful logs (line 271)
            relationships_query = "EVALUATE CALCULATETABLE( SELECTCOLUMNS(__def_Relationships, [Relationship]), __def_Relationships[IsActive] = TRUE() )"
            
            result = client.execute_dax_query(workspace['id'], dataset['id'], relationships_query)
            
            # Parse result exactly like execute_custom_dax does
            results = result.get("results", [])
            if results and "tables" in results[0]:
                tables_data = results[0]["tables"]
                if tables_data and len(tables_data) > 0 and "rows" in tables_data[0]:
                    rows = tables_data[0]["rows"]
                    output += f"üéØ DISCOVERED {len(rows)} ACTIVE RELATIONSHIPS:\n\n"
                    
                    # Format exactly like successful response
                    for i, row in enumerate(rows, 1):
                        relationship = row.get('__def_Relationships[Relationship]', '')
                        output += f"{i}. {relationship}\n"
                    
                    output += f"\nüí° RELATIONSHIP ANALYSIS:\n"
                    output += f"‚Ä¢ These relationships define how tables connect\n"
                    output += f"‚Ä¢ Active relationships are used in DAX calculations\n"
                    output += f"‚Ä¢ Essential for understanding data model structure\n"
                    output += f"‚Ä¢ Use these for writing proper DAX queries\n"
                    
                    # Analyze fact table connections
                    fact_relationships = [row for row in rows if 'Journals' in row.get('__def_Relationships[Relationship]', '')]
                    if fact_relationships:
                        output += f"\nüìä FACT TABLE CONNECTIONS:\n"
                        for rel_row in fact_relationships:
                            relationship = rel_row.get('__def_Relationships[Relationship]', '')
                            output += f"  ‚Ä¢ {relationship}\n"
                        
                else:
                    output += "‚ùå No relationships found in response structure\n"
            else:
                output += "‚ùå No relationships discovered\n"
                output += "Possible issues:\n"
                output += "‚Ä¢ Model permissions restricted\n"
                output += "‚Ä¢ Dataset refresh needed\n"
                output += "‚Ä¢ Network connectivity problems\n"
            
            return output
            
        except Exception as e:
            error_msg = f"‚ùå Auto-discovery failed for relationships: {str(e)}"
            mcp_logger.error(error_msg)
            return error_msg
    
    @mcp.tool()
    def select_powerbi_model() -> str:
        """
        Show available Power BI workspaces and datasets for user selection.
        """
        try:
            mcp_logger.info("Showing Power BI model selection options")
            
            client = get_powerbi_client()
            workspaces = client.get_workspaces()
            
            output = "üöÄ AVAILABLE POWER BI MODELS\n"
            output += "=" * 50 + "\n\n"
            
            if workspaces:
                for workspace in workspaces:
                    workspace_name = workspace.get('name', '<NO NAME>')
                    output += f"üìä WORKSPACE: {workspace_name}\n"
                    output += f"   ID: {workspace['id']}\n"
                    
                    try:
                        datasets = client.get_datasets(workspace['id'])
                        if datasets:
                            output += f"   üìã DATASETS ({len(datasets)}):\n"
                            for dataset in datasets:
                                dataset_name = dataset.get('name', '<NO NAME>')
                                dataset_id = dataset.get('id', '')
                                target_storage_mode = dataset.get('targetStorageMode', 'Unknown')
                                output += f"      ‚Ä¢ {dataset_name}\n"
                                output += f"        ID: {dataset_id}\n"
                                output += f"        Mode: {target_storage_mode}\n"
                        else:
                            output += f"   üìã DATASETS: None available\n"
                    except Exception as dataset_error:
                        output += f"   üìã DATASETS: Error retrieving ({str(dataset_error)[:50]}...)\n"
                    
                    output += "\n"
            else:
                output += "‚ùå No workspaces found\n\n"
            
            output += "üí° TO USE A MODEL:\n"
            output += "   ‚Ä¢ Use list_datasets(workspace_name='<workspace_name>') for detailed dataset list\n"
            output += "   ‚Ä¢ Use get_model_info(workspace_name='<workspace>', dataset_name='<dataset>') for model details\n"
            output += "   ‚Ä¢ Use discover_measures(workspace_name='<workspace>', dataset_name='<dataset>') for measures\n\n"
            
            output += "üìù RECOMMENDED WORKFLOW:\n"
            output += "   1. Choose a workspace and dataset from the list above\n"
            output += "   2. Use get_model_info() to understand the data structure\n"
            output += "   3. Use discover_measures() to see available financial metrics\n"
            
            return output
            
        except Exception as e:
            error_msg = f"‚ùå Error displaying Power BI models: {str(e)}"
            mcp_logger.error(error_msg)
            return error_msg
    
    @mcp.tool()
    def discover_model(
        workspace_name: str,
        dataset_name: str,
        force_refresh: bool = False
    ) -> str:
        """
        Run complete model discovery using exact working DAX queries.
        """
        try:
            mcp_logger.info(f"Running complete model discovery for {workspace_name}/{dataset_name}")
            
            output = f"üöÄ COMPLETE MODEL DISCOVERY\n"
            output += f"Workspace: {workspace_name}\n"
            output += f"Dataset: {dataset_name}\n"
            output += "=" * 60 + "\n\n"
            
            results = {}
            
            # 1. Workspace Info
            output += "1Ô∏è‚É£ DISCOVERING WORKSPACE INFO...\n"
            try:
                auto_discover_workspace_info(workspace_name, dataset_name)
                results['workspace'] = 'Success'
                output += "‚úÖ Workspace discovery completed\n\n"
            except Exception as e:
                results['workspace'] = f'Failed: {str(e)}'
                output += f"‚ùå Workspace discovery failed: {e}\n\n"
            
            # 2. Measures  
            output += "2Ô∏è‚É£ DISCOVERING MEASURES...\n"
            try:
                auto_discover_measures(workspace_name, dataset_name)
                results['measures'] = 'Success'
                output += "‚úÖ Measures discovery completed\n\n"
            except Exception as e:
                results['measures'] = f'Failed: {str(e)}'
                output += f"‚ùå Measures discovery failed: {e}\n\n"
            
            # 3. Schema
            output += "3Ô∏è‚É£ DISCOVERING SCHEMA...\n"
            try:
                auto_discover_schema(workspace_name, dataset_name)
                results['schema'] = 'Success'
                output += "‚úÖ Schema discovery completed\n\n"
            except Exception as e:
                results['schema'] = f'Failed: {str(e)}'
                output += f"‚ùå Schema discovery failed: {e}\n\n"
            
            # 4. Relationships
            output += "4Ô∏è‚É£ DISCOVERING RELATIONSHIPS...\n"
            try:
                auto_discover_relationships(workspace_name, dataset_name)
                results['relationships'] = 'Success'
                output += "‚úÖ Relationships discovery completed\n\n"
            except Exception as e:
                results['relationships'] = f'Failed: {str(e)}'
                output += f"‚ùå Relationships discovery failed: {e}\n\n"
            
            # Summary
            successful = sum(1 for r in results.values() if r == 'Success')
            output += f"üìä DISCOVERY SUMMARY:\n"
            output += f"‚Ä¢ Successful: {successful}/4 functions\n"
            output += f"‚Ä¢ Workspace: {results.get('workspace', 'Unknown')}\n"
            output += f"‚Ä¢ Measures: {results.get('measures', 'Unknown')}\n"
            output += f"‚Ä¢ Schema: {results.get('schema', 'Unknown')}\n"
            output += f"‚Ä¢ Relationships: {results.get('relationships', 'Unknown')}\n\n"
            
            if successful == 4:
                output += "üéâ ALL DISCOVERY FUNCTIONS COMPLETED SUCCESSFULLY!\n"
                output += "‚Ä¢ Data retrieved using proven DAX query methods\n"
                output += "‚Ä¢ No caching - always latest information\n"
                output += "‚Ä¢ Ready for financial analysis\n"
            elif successful > 0:
                output += "‚ö†Ô∏è PARTIAL SUCCESS - Some functions completed\n"
                output += "‚Ä¢ You can still proceed with available data\n"
            else:
                output += "‚ùå ALL DISCOVERY FUNCTIONS FAILED\n"
                output += "‚Ä¢ Check Power BI connectivity and permissions\n"
            
            return output
            
        except Exception as e:
            error_msg = f"‚ùå Complete discovery failed: {str(e)}"
            mcp_logger.error(error_msg)
            return error_msg